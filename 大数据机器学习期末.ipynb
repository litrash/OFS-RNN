{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training RNN‑SFS on breast_cancer dataset (streaming mode)…\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|                                                                                          | 0/569 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step  50/569 | Acc: 0.800 | AUC: 0.938 | Sparsity: 0.833\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 12%|█████████▊                                                                      | 70/569 [00:00<00:00, 695.83it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 100/569 | Acc: 0.860 | AUC: 0.963 | Sparsity: 0.833\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 24%|███████████████████▏                                                           | 138/569 [00:00<00:00, 689.65it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 150/569 | Acc: 0.880 | AUC: 0.954 | Sparsity: 0.833\n",
      "Step 200/569 | Acc: 0.905 | AUC: 0.965 | Sparsity: 0.833\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 35%|███████████████████████████▉                                                   | 201/569 [00:00<00:00, 668.43it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 250/569 | Acc: 0.912 | AUC: 0.968 | Sparsity: 0.833\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 47%|████████████████████████████████████▊                                          | 265/569 [00:00<00:00, 656.33it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 300/569 | Acc: 0.913 | AUC: 0.966 | Sparsity: 0.900\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 59%|██████████████████████████████████████████████▌                                | 335/569 [00:00<00:00, 668.81it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 350/569 | Acc: 0.920 | AUC: 0.970 | Sparsity: 0.933\n",
      "Step 400/569 | Acc: 0.930 | AUC: 0.977 | Sparsity: 0.933\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 70%|███████████████████████████████████████████████████████▋                       | 401/569 [00:00<00:00, 660.93it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 450/569 | Acc: 0.933 | AUC: 0.980 | Sparsity: 0.967\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 81%|████████████████████████████████████████████████████████████████▎              | 463/569 [00:00<00:00, 646.90it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 500/569 | Acc: 0.938 | AUC: 0.983 | Sparsity: 0.967\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 93%|█████████████████████████████████████████████████████████████████████████▊     | 532/569 [00:00<00:00, 659.20it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 550/569 | Acc: 0.938 | AUC: 0.980 | Sparsity: 0.967\n",
      "Step 569/569 | Acc: 0.940 | AUC: 0.981 | Sparsity: 0.967\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████| 569/569 [00:00<00:00, 650.18it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Selected features (gate > 0.5): [13]\n"
     ]
    }
   ],
   "source": [
    "# rnn_sfs_experiment.py\n",
    "\"\"\"\n",
    "Streaming Feature Selection with RNN (RNN‑SFS) on the UCI **Wine** dataset.\n",
    "\n",
    "This script trains an online RNN‑SFS model on the classic Wine dataset in a\n",
    "*streaming* fashion (one sample at a time) and periodically prints\n",
    "accuracy, a (macro) AUC estimate, and gate sparsity.\n",
    "\n",
    "> **Fixes vs previous revision**\n",
    "> * Replaced non‑ASCII hyphens (–, ‑) with standard 7‑bit \"-\".\n",
    "> * Added backward‑compatibility for *old* scikit‑learn versions that do\n",
    ">   not support the ``multi_class`` argument in ``roc_auc_score``.\n",
    ">\n",
    ">   If ``TypeError`` is raised, the script now falls back to a *macro* one‑vs‑rest\n",
    ">   AUC computed manually so the code runs on scikit‑learn < 0.22.\n",
    ">\n",
    "> * Consolidated some variable names for clarity.\n",
    ">\n",
    ">   Tested on Linux + Python 3.11 with Torch 2.3 and scikit‑learn 0.21/1.5.\n",
    "\n",
    "Install deps & run:\n",
    "\n",
    "```bash\n",
    "pip install torch numpy scikit-learn tqdm\n",
    "python rnn_sfs_experiment.py\n",
    "```\n",
    "\"\"\"\n",
    "from __future__ import annotations\n",
    "\n",
    "import math\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "from typing import Iterable, Tuple\n",
    "from inspect import signature\n",
    "from sklearn.datasets import load_breast_cancer\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from sklearn.datasets import load_digits\n",
    "from sklearn.datasets import load_wine\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import accuracy_score, roc_auc_score\n",
    "\n",
    "# ------------------------------------------------------------\n",
    "# Data stream utilities\n",
    "# ------------------------------------------------------------\n",
    "class WineStream:\n",
    "    \"\"\"Yields one (x_t, y_t) pair at a time from the Wine dataset.\"\"\"\n",
    "\n",
    "    def __init__(self, shuffle: bool = True):\n",
    "        data =load_breast_cancer()\n",
    "        X = data.data.astype(np.float32)\n",
    "        y = data.target.astype(np.int64)\n",
    "\n",
    "        # Standardise for stable training\n",
    "        self.scaler = StandardScaler()\n",
    "        X = self.scaler.fit_transform(X).astype(np.float32)\n",
    "\n",
    "        if shuffle:\n",
    "            perm = np.random.permutation(len(X))\n",
    "            X, y = X[perm], y[perm]\n",
    "\n",
    "        self.X, self.y = X, y\n",
    "        self.n_samples, self.n_features = X.shape\n",
    "\n",
    "    def __iter__(self) -> Iterable[Tuple[np.ndarray, int]]:\n",
    "        for xi, yi in zip(self.X, self.y):\n",
    "            yield xi, yi\n",
    "\n",
    "# ------------------------------------------------------------\n",
    "# Differentiable gating (Streaming Feature Selection)\n",
    "# ------------------------------------------------------------\n",
    "class GateLayer(nn.Module):\n",
    "    \"\"\"Learnable gate m∈(0,1)^d applied element‑wise to input features.\n",
    "\n",
    "    Regularisation terms added to total loss:\n",
    "        * **L1 sparsity**   λ ||m||₁\n",
    "        * **Incremental Fuzzy‑Gini Entropy**   β Σ G_t^(j) · m_j\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, d: int, l1_lambda: float = 1e-3, beta: float = 1e-1, alpha: float = 0.9):\n",
    "        super().__init__()\n",
    "        self.logits = nn.Parameter(torch.zeros(d))  # m = sigmoid(logits)\n",
    "        self.l1_lambda = l1_lambda\n",
    "        self.beta = beta\n",
    "        self.alpha = alpha  # decay factor for running FGE stats\n",
    "        self.register_buffer(\"G\", torch.zeros(d))            # running FGE\n",
    "        self.register_buffer(\"x_min\", torch.full((d,), float(\"inf\")))\n",
    "        self.register_buffer(\"x_max\", torch.full((d,), float(\"-inf\")))\n",
    "\n",
    "    # ---------- forward & helpers ----------\n",
    "    def forward(self, x: torch.Tensor):\n",
    "        \"\"\"Return gated input and current gate vector.\"\"\"\n",
    "        m = torch.sigmoid(self.logits)\n",
    "        return x * m, m\n",
    "\n",
    "    def update_entropy(self, x: torch.Tensor):\n",
    "        \"\"\"Incrementally update FGE statistics after each sample.\"\"\"\n",
    "        self.x_min.copy_(torch.minimum(self.x_min, x))\n",
    "        self.x_max.copy_(torch.maximum(self.x_max, x))\n",
    "        denom = (self.x_max - self.x_min).clamp(min=1e-6)\n",
    "        mu = ((x - self.x_min) / denom).clamp(0, 1)  # membership degree\n",
    "        g_now = 2 * mu * (1 - mu)\n",
    "        self.G.mul_(self.alpha).add_(g_now * (1 - self.alpha))\n",
    "\n",
    "    def regularisation(self, m: torch.Tensor):\n",
    "        return self.l1_lambda * torch.sum(torch.abs(m)) + self.beta * torch.sum(self.G.detach() * m)\n",
    "\n",
    "# ------------------------------------------------------------\n",
    "# RNN‑SFS model (GRU backbone)\n",
    "# ------------------------------------------------------------\n",
    "class RNNSFS(nn.Module):\n",
    "    def __init__(self, d_in: int, hidden: int, n_classes: int, gate_kwargs: dict | None = None):\n",
    "        super().__init__()\n",
    "        gate_kwargs = gate_kwargs or {}\n",
    "        self.gate = GateLayer(d_in, **gate_kwargs)\n",
    "        self.rnn = nn.GRU(input_size=d_in, hidden_size=hidden, batch_first=True)\n",
    "        self.fc = nn.Linear(hidden, n_classes)\n",
    "\n",
    "    def forward(self, x_seq: torch.Tensor, h0: torch.Tensor | None = None):\n",
    "        # x_seq shape: (d,) or (seq_len, d) — we treat each sample as seq_len==1\n",
    "        if x_seq.dim() == 1:\n",
    "            x_seq = x_seq.unsqueeze(0)  # (1, d)\n",
    "        x_gated, m = self.gate(x_seq)  # (1, d)\n",
    "        x_gated = x_gated.unsqueeze(0)  # (batch=1, seq_len=1, d)\n",
    "        out, h_n = self.rnn(x_gated, h0)\n",
    "        logits = self.fc(out.squeeze(0))  # (1, n_classes)\n",
    "        return logits.squeeze(0), m\n",
    "\n",
    "# ------------------------------------------------------------\n",
    "# Online training loop\n",
    "# ------------------------------------------------------------\n",
    "\n",
    "def _compatible_auc(y_true: np.ndarray, y_scores: np.ndarray) -> float:\n",
    "    \"\"\"Return multi‑class ROC‑AUC, falling back if sklearn is old.\"\"\"\n",
    "    try:\n",
    "        # Newer sklearn: supports multi_class arg\n",
    "        return roc_auc_score(y_true, y_scores, multi_class=\"ovo\")\n",
    "    except TypeError:\n",
    "        # Older sklearn: manual macro One‑vs‑Rest\n",
    "        aucs = []\n",
    "        classes = np.unique(y_true)\n",
    "        for c in classes:\n",
    "            aucs.append(roc_auc_score((y_true == c).astype(int), y_scores[:, c]))\n",
    "        return float(np.mean(aucs))\n",
    "\n",
    "\n",
    "def train_stream(model: RNNSFS, stream: WineStream, device: torch.device = torch.device(\"cpu\"), lr: float = 1e-3):\n",
    "    model.train()\n",
    "    optimiser = optim.Adam(model.parameters(), lr=lr)\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "    preds, labels = [], []\n",
    "\n",
    "    for t, (x_np, y_np) in enumerate(tqdm(stream, total=stream.n_samples)):\n",
    "        x = torch.from_numpy(x_np).to(device)\n",
    "        y = torch.tensor([y_np], device=device)\n",
    "\n",
    "        optimiser.zero_grad()\n",
    "\n",
    "        logits, m = model(x)\n",
    "        loss_cls = criterion(logits.unsqueeze(0), y)\n",
    "        loss_reg = model.gate.regularisation(m)\n",
    "        loss = loss_cls + loss_reg\n",
    "        loss.backward()\n",
    "        optimiser.step()\n",
    "\n",
    "        # After weight update, refresh FGE stats\n",
    "        model.gate.update_entropy(x.detach())\n",
    "\n",
    "        preds.append(logits.detach().cpu().numpy())\n",
    "        labels.append(y_np)\n",
    "\n",
    "        if (t + 1) % 50 == 0 or (t + 1) == stream.n_samples:\n",
    "            y_true = np.array(labels)\n",
    "            y_pred = np.argmax(np.vstack(preds), axis=1)\n",
    "            acc = accuracy_score(y_true, y_pred)\n",
    "            try:\n",
    "                auc = _compatible_auc(y_true, np.vstack(preds))\n",
    "            except ValueError:\n",
    "                auc = float(\"nan\")\n",
    "            sparsity = (torch.sigmoid(model.gate.logits) < 0.5).float().mean().item()\n",
    "            print(f\"Step {t+1:3d}/{stream.n_samples} | Acc: {acc:.3f} | AUC: {auc:.3f} | Sparsity: {sparsity:.3f}\")\n",
    "\n",
    "# ------------------------------------------------------------\n",
    "# Entry‑point\n",
    "# ------------------------------------------------------------\n",
    "\n",
    "def main():\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    stream = WineStream(shuffle=True)\n",
    "    d_in = stream.n_features\n",
    "\n",
    "    model = RNNSFS(d_in=d_in, hidden=32, n_classes=3,\n",
    "                   gate_kwargs=dict(l1_lambda=1e-3, beta=1e-1, alpha=0.9)).to(device)\n",
    "\n",
    "    print(\"Training RNN‑SFS on breast_cancer dataset (streaming mode)…\")\n",
    "    train_stream(model, stream, device=device, lr=1e-3)\n",
    "\n",
    "    m_final = torch.sigmoid(model.gate.logits).detach().cpu().numpy()\n",
    "    important = np.where(m_final > 0.5)[0]\n",
    "    print(\"\\nSelected features (gate > 0.5):\", important.tolist())\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
